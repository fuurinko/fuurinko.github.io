<!DOCTYPE html>
<!--[if lte IE 8 ]>
<html class="ie" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-US" lang="en-US">
<![endif]-->
<!--[if (gte IE 9)|!(IE)]><!-->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh-CN" lang="zh-CN">
<!--<![endif]-->

<head>

  <title>ml_RetinaNet代码分析 | Rin</title>
  <!-- Meta data -->
    <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" >
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="generator" content="Rin">
    <meta name="author" content="Rin777">
    <meta name="description" content="" />
    <meta name="keywords" content="" />

    <!-- Favicon, (keep icon in root folder) -->
    <link rel="Shortcut Icon" href="/img/favicon.ico" type="image/ico">

    <link rel="alternate" href="/atom.xml" title="Rin" type="application/atom+xml">
    <link rel="stylesheet" href="/css/all.css" media="screen" type="text/css">
    

    <!--[if IE 8]>
    <link rel="stylesheet" type="text/css" href="/css/ie8.css" />
    <![endif]-->

    <!-- jQuery | Load our jQuery, with an alternative source fallback to a local version if request is unavailable -->
    <script src="/js/jquery-1.11.1.min.js"></script>
    <script>window.jQuery || document.write('<script src="js/jquery-1.11.1.min.js"><\/script>')</script>

    <!-- Load these in the <head> for quicker IE8+ load times -->
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="/js/html5shiv.min.js"></script>
    <script src="/js/respond.min.js"></script>
    <![endif]-->

  
  
  

  <style>.col-md-8.col-md-offset-2.opening-statement img{display:none;}</style>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><link rel="stylesheet" href="/css/prism.css" type="text/css"></head>

<!--
<body class="post-template">
-->
<body id="index" class="lightnav animsition">
      <!-- ============================ Off-canvas navigation =========================== -->

    <div class="sb-slidebar sb-right sb-style-overlay sb-momentum-scrolling">
        <div class="sb-close" aria-label="Close Menu" aria-hidden="true">
            <img src="/img/close.png" alt="Close"/>
        </div>
        <!-- Lists in Slidebars -->
        <ul class="sb-menu">
            <li><a href="/" class="animsition-link" title="Home">Home</a></li>
            <li><a href="/archives" class="animsition-link" title="archive">archives</a></li>
            <!-- Dropdown Menu -->
			 
            
        	<li>
        		<a class="sb-toggle-submenu">Categories<span class="sb-caret"></span></a>
            	<ul class="sb-submenu">
				  	
				    <li><a href="/categories/AUDITION/" class="animsition-link">AUDITION<small>(23)</small></a></li>
				    
				    <li><a href="/categories/Binary-security/" class="animsition-link">Binary_security<small>(101)</small></a></li>
				    
				    <li><a href="/categories/CSAPP-LAB/" class="animsition-link">CSAPP LAB<small>(1)</small></a></li>
				    
				    <li><a href="/categories/EE/" class="animsition-link">EE<small>(5)</small></a></li>
				    
				    <li><a href="/categories/EN/" class="animsition-link">EN<small>(1)</small></a></li>
				    
				    <li><a href="/categories/Linux/" class="animsition-link">Linux<small>(1)</small></a></li>
				    
				    <li><a href="/categories/ML/" class="animsition-link">ML<small>(53)</small></a></li>
				    
				    <li><a href="/categories/PWN-COLLEGE/" class="animsition-link">PWN.COLLEGE<small>(1)</small></a></li>
				    
				</ul>
        	</li>
			
            
            <li>
                <a class="sb-toggle-submenu">Links<span class="sb-caret"></span></a>
                <ul class="sb-submenu">
                    
                    <li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Wh4y1o7Xh" class="animsition-link">INNOUT「系统过载」SYSTEM专场演出</a></li>
                    
                    <li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Kv411574g" class="animsition-link">普通周末 肖骏个人音乐演出 《边境Frontier》</a></li>
                    
                </ul>
            </li>
            
        </ul>
        <!-- Lists in Slidebars -->
        <ul class="sb-menu secondary">
            
            <li><a href="javascript:;" class="popup-trigger" title="Search"><span class="search-icon"></span>Search</a></li>
            
            <li><a href="/about.html" class="animsition-link" title="about">About</a></li>
            <li><a href="/atom.xml" class="animsition-link" title="rss">RSS</a></li>
        </ul>
    </div>
    
    <!-- ============================ END Off-canvas navigation =========================== -->

    <!-- ============================ #sb-site Main Page Wrapper =========================== -->

    <div id="sb-site">
        <!-- #sb-site - All page content should be contained within this id, except the off-canvas navigation itself -->

        <!-- ============================ Header & Logo bar =========================== -->

        <div id="navigation" class="navbar navbar-fixed-top">
            <div class="navbar-inner">
                <div class="container">
                    <!-- Nav logo -->
                    <div class="logo">
                        <a href="/" title="Logo" class="animsition-link">
                         <img src="https://rin777-1306176007.cos.ap-nanjing.myqcloud.com/98f52bd6gy1hfqk9tjohfg20xc0xc7e6.gif" alt="Logo" width="35px;"/> 
                        </a>
                    </div>
                    <!-- // Nav logo -->
                    <!-- Info-bar -->
                    <nav>
                        <ul class="nav">
                            <li><a href="/" class="animsition-link">Rin</a></li>
                            <li class="nolink"><span>Always </span>Creative.</li>
                            
                            <li><a href="https://github.com/" title="Github" target="_blank"><i class="icon-github"></i></a></li>
                            
                            
                            
                            
                            
                            <li class="nolink"><span>Welcome!</span></li>
                        </ul>
                    </nav>
                    <!--// Info-bar -->
                </div>
                <!-- // .container -->
                <div class="learnmore sb-toggle-right">More</div>
                <button type="button" class="navbar-toggle menu-icon sb-toggle-right" title="More">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar before"></span>
                <span class="icon-bar main"></span>
                <span class="icon-bar after"></span>
                </button>
            </div>
            <!-- // .navbar-inner -->
        </div>

        <!-- ============================ Header & Logo bar =========================== -->


      
<section id="intro">
    <div class="container">
        <div class="row col-md-offset-2">
            <div class="col-md-8">
    			<span class="post-meta">
      <time datetime="2023-11-01T09:30:29.640Z" itemprop="datePublished">
          2023-11-01
      </time>
    
    
    | 
    <a href='/tags/mess/'>mess</a>
    
    
</span>
                <h1>ml_RetinaNet代码分析</h1>
            </div>
        </div>
        <div class="col-md-8 col-md-offset-2">
      		<h1><span id="1-train">1 train</span></h1><h2><span id="11-数据集">1.1 数据集</span></h2><p>定义命令行参数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">parser = argparse.ArgumentParser(description=<span class="string">&#x27;Simple training script for training a RetinaNet network.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--dataset&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Dataset type, must be one of csv or coco.&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--coco_path&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Path to COCO directory&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--csv_train&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Path to file containing training annotations (see readme)&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--csv_classes&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Path to file containing class list (see readme)&#x27;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--csv_val&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Path to file containing validation annotations (optional, see readme)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--depth&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Resnet depth, must be one of 18, 34, 50, 101, 152&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">50</span>)</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--epochs&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Number of epochs&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">parser = parser.parse_args(args)</span><br></pre></td></tr></table></figure></p>
<p>数据集加载<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">dataset_train = CSVDataset(train_file=parser.csv_train, class_list=parser.csv_classes,</span><br><span class="line">                           transform=transforms.Compose([Normalizer(), Augmenter(), Resizer()]))</span><br></pre></td></tr></table></figure></p>
<p>具体的加载函数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CSVDataset</span>(<span class="params">Dataset</span>):</span></span><br></pre></td></tr></table></figure></p>
<p>数据集from <code>dataset_train</code>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">img = self.load_image(idx)</span><br><span class="line">annot = self.load_annotations(idx)</span><br><span class="line">sample = &#123;<span class="string">&#x27;img&#x27;</span>: img, <span class="string">&#x27;annot&#x27;</span>: annot&#125;</span><br></pre></td></tr></table></figure></p>
<h2><span id="12-采样小批量">1.2 采样小批量</span></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sampler = AspectRatioBasedSampler(dataset_train, batch_size=<span class="number">2</span>, drop_last=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AspectRatioBasedSampler</span>(<span class="params">Sampler</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, data_source, batch_size, drop_last</span>):</span></span><br><span class="line">        self.data_source = data_source</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.drop_last = drop_last</span><br><span class="line">        self.groups = self.group_images()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span>(<span class="params">self</span>):</span></span><br><span class="line">        random.shuffle(self.groups)</span><br><span class="line">        <span class="keyword">for</span> group <span class="keyword">in</span> self.groups:</span><br><span class="line">            <span class="keyword">yield</span> group</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.drop_last:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">len</span>(self.data_source) // self.batch_size</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> (<span class="built_in">len</span>(self.data_source) + self.batch_size - <span class="number">1</span>) // self.batch_size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">group_images</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># determine the order of the images</span></span><br><span class="line">        order = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="built_in">len</span>(self.data_source)))</span><br><span class="line">        order.sort(key=<span class="keyword">lambda</span> x: self.data_source.image_aspect_ratio(x))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># divide into groups, one group = one batch</span></span><br><span class="line">        <span class="keyword">return</span> [[order[x % <span class="built_in">len</span>(order)] <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(i, i + self.batch_size)] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(order), self.batch_size)]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">dataloader_train = DataLoader(dataset_train, num_workers=<span class="number">3</span>, collate_fn=collater, batch_sampler=sampler)</span><br><span class="line"><span class="comment">#num_worker = 并行子进程数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#collate_fn：将samples处理进小批量</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#batch_sampler=sampler 小批量的idx</span></span><br></pre></td></tr></table></figure>
<p>其中<code>collate_fn</code>函数为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collater</span>(<span class="params">data</span>):</span></span><br><span class="line"></span><br><span class="line">    imgs = [s[<span class="string">&#x27;img&#x27;</span>] <span class="keyword">for</span> s <span class="keyword">in</span> data]</span><br><span class="line">    annots = [s[<span class="string">&#x27;annot&#x27;</span>] <span class="keyword">for</span> s <span class="keyword">in</span> data]</span><br><span class="line">    scales = [s[<span class="string">&#x27;scale&#x27;</span>] <span class="keyword">for</span> s <span class="keyword">in</span> data]</span><br><span class="line">        </span><br><span class="line">    widths = [<span class="built_in">int</span>(s.shape[<span class="number">0</span>]) <span class="keyword">for</span> s <span class="keyword">in</span> imgs]</span><br><span class="line">    heights = [<span class="built_in">int</span>(s.shape[<span class="number">1</span>]) <span class="keyword">for</span> s <span class="keyword">in</span> imgs]</span><br><span class="line">    batch_size = <span class="built_in">len</span>(imgs)</span><br><span class="line"></span><br><span class="line">    max_width = np.array(widths).<span class="built_in">max</span>()</span><br><span class="line">    max_height = np.array(heights).<span class="built_in">max</span>()</span><br><span class="line"></span><br><span class="line">    padded_imgs = torch.zeros(batch_size, max_width, max_height, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(batch_size):</span><br><span class="line">        img = imgs[i]</span><br><span class="line">        padded_imgs[i, :<span class="built_in">int</span>(img.shape[<span class="number">0</span>]), :<span class="built_in">int</span>(img.shape[<span class="number">1</span>]), :] = img</span><br><span class="line"></span><br><span class="line">    max_num_annots = <span class="built_in">max</span>(annot.shape[<span class="number">0</span>] <span class="keyword">for</span> annot <span class="keyword">in</span> annots)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> max_num_annots &gt; <span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">        annot_padded = torch.ones((<span class="built_in">len</span>(annots), max_num_annots, <span class="number">5</span>)) * -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> max_num_annots &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">for</span> idx, annot <span class="keyword">in</span> <span class="built_in">enumerate</span>(annots):</span><br><span class="line">                <span class="comment">#print(annot.shape)</span></span><br><span class="line">                <span class="keyword">if</span> annot.shape[<span class="number">0</span>] &gt; <span class="number">0</span>:</span><br><span class="line">                    annot_padded[idx, :annot.shape[<span class="number">0</span>], :] = annot</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        annot_padded = torch.ones((<span class="built_in">len</span>(annots), <span class="number">1</span>, <span class="number">5</span>)) * -<span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    padded_imgs = padded_imgs.permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&#x27;img&#x27;</span>: padded_imgs, <span class="string">&#x27;annot&#x27;</span>: annot_padded, <span class="string">&#x27;scale&#x27;</span>: scales&#125;</span><br></pre></td></tr></table></figure></p>
<p>然后是加载val，策略和train没区别<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> dataset_val <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        sampler_val = AspectRatioBasedSampler(dataset_val, batch_size=<span class="number">1</span>, drop_last=<span class="literal">False</span>)</span><br><span class="line">        dataloader_val = DataLoader(dataset_val, num_workers=<span class="number">3</span>, collate_fn=collater, batch_sampler=sampler_val)</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h2><span id="13-构造模型">1.3 构造模型</span></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create the model</span></span><br><span class="line">  <span class="keyword">if</span> parser.depth == <span class="number">18</span>:</span><br><span class="line">      retinanet = model.resnet18(num_classes=dataset_train.num_classes(), pretrained=<span class="literal">True</span>)</span><br><span class="line">  <span class="keyword">elif</span> parser.depth == <span class="number">34</span>:</span><br><span class="line">      retinanet = model.resnet34(num_classes=dataset_train.num_classes(), pretrained=<span class="literal">True</span>)</span><br><span class="line">  <span class="keyword">elif</span> parser.depth == <span class="number">50</span>:</span><br><span class="line">      retinanet = model.resnet50(num_classes=dataset_train.num_classes(), pretrained=<span class="literal">True</span>)</span><br><span class="line">  <span class="keyword">elif</span> parser.depth == <span class="number">101</span>:</span><br><span class="line">      retinanet = model.resnet101(num_classes=dataset_train.num_classes(), pretrained=<span class="literal">True</span>)</span><br><span class="line">  <span class="keyword">elif</span> parser.depth == <span class="number">152</span>:</span><br><span class="line">      retinanet = model.resnet152(num_classes=dataset_train.num_classes(), pretrained=<span class="literal">True</span>)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">raise</span> ValueError(<span class="string">&#x27;Unsupported model depth, must be one of 18, 34, 50, 101, 152&#x27;</span>)</span><br><span class="line">  retinanet  = torch.load(<span class="string">&#x27;/root/autodl-fs/weight/RetinaNet(No HEM)/csv_retinanet_51.pt&#x27;</span>)</span><br><span class="line">  use_gpu = <span class="literal">True</span></span><br><span class="line">  <span class="comment">#有gpu用gpu</span></span><br><span class="line">  <span class="keyword">if</span> use_gpu:</span><br><span class="line">      <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">          retinanet = retinanet.cuda()</span><br><span class="line">  <span class="comment">#有多gpu用多gpu</span></span><br><span class="line">  <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">      retinanet = torch.nn.DataParallel(retinanet).cuda()</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">      retinanet = torch.nn.DataParallel(retinanet)</span><br><span class="line"></span><br><span class="line">  retinanet.training = <span class="literal">True</span></span><br><span class="line">  <span class="comment">#定义优化器</span></span><br><span class="line">  optimizer = optim.Adam(retinanet.parameters(), lr=<span class="number">1e-5</span>)</span><br><span class="line">  <span class="comment">#自动调整学习率</span></span><br><span class="line">  scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=<span class="number">3</span>, verbose=<span class="literal">True</span>)</span><br><span class="line">  <span class="comment">#保存历史loss</span></span><br><span class="line">  loss_hist = collections.deque(maxlen=<span class="number">500</span>)</span><br><span class="line">  <span class="comment">#开始训练</span></span><br><span class="line">  retinanet.train()</span><br><span class="line">  <span class="comment">#冻结bn层参数更新</span></span><br><span class="line">  retinanet.module.freeze_bn()</span><br><span class="line"></span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&#x27;Num training images: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(dataset_train)))</span><br><span class="line"></span><br><span class="line">  class_weights = torch.tensor([<span class="number">0.5</span>, <span class="number">0.1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,<span class="number">1</span>]).<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">      class_weights = class_weights.cuda()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> epoch_num <span class="keyword">in</span> <span class="built_in">range</span>(parser.epochs):</span><br><span class="line"></span><br><span class="line">      retinanet.train()</span><br><span class="line">      retinanet.module.freeze_bn()</span><br><span class="line">      <span class="comment">#开始训练</span></span><br><span class="line"></span><br><span class="line">      epoch_loss = []</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> iter_num, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader_train):</span><br><span class="line">          <span class="comment">#iter_num：每个批量的list</span></span><br><span class="line">          <span class="comment">#data：就data</span></span><br><span class="line">          <span class="keyword">try</span>:</span><br><span class="line">              optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">              <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">                  classification_loss, regression_loss = retinanet([data[<span class="string">&#x27;img&#x27;</span>].cuda().<span class="built_in">float</span>(), data[<span class="string">&#x27;annot&#x27;</span>]])</span><br><span class="line">                  <span class="comment">#计算loss</span></span><br><span class="line">              <span class="keyword">else</span>:</span><br><span class="line">                  classification_loss, regression_loss = retinanet([data[<span class="string">&#x27;img&#x27;</span>].<span class="built_in">float</span>(), data[<span class="string">&#x27;annot&#x27;</span>]])</span><br><span class="line">              <span class="comment">#print(classification_loss.shape)</span></span><br><span class="line">              <span class="comment">#classification_loss = class_loss_weighted.mean()</span></span><br><span class="line">              <span class="comment">#算均值</span></span><br><span class="line">              classification_loss = classification_loss.mean()</span><br><span class="line">              regression_loss = regression_loss.mean()</span><br><span class="line">              loss = classification_loss + regression_loss</span><br><span class="line">              <span class="comment">#同时优化两个loss</span></span><br><span class="line"></span><br><span class="line">              <span class="keyword">if</span> <span class="built_in">bool</span>(loss == <span class="number">0</span>):</span><br><span class="line">                  <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">              loss.backward()</span><br><span class="line">              <span class="comment">#反向传播</span></span><br><span class="line"></span><br><span class="line">              torch.nn.utils.clip_grad_norm_(retinanet.parameters(), <span class="number">0.1</span>)</span><br><span class="line">              <span class="comment">#防止梯度爆炸</span></span><br><span class="line"></span><br><span class="line">              optimizer.step()</span><br><span class="line">              <span class="comment">#参数更新</span></span><br><span class="line">              loss_hist.append(<span class="built_in">float</span>(loss))</span><br><span class="line">              epoch_loss.append(<span class="built_in">float</span>(loss))</span><br><span class="line"></span><br><span class="line">              <span class="built_in">print</span>(</span><br><span class="line">                  <span class="string">&#x27;Epoch: &#123;&#125; | Iteration: &#123;&#125; | Classification loss: &#123;:1.5f&#125; | Regression loss: &#123;:1.5f&#125; | Running loss: &#123;:1.5f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                      epoch_num, iter_num, <span class="built_in">float</span>(classification_loss), <span class="built_in">float</span>(regression_loss), np.mean(loss_hist)))</span><br><span class="line"></span><br><span class="line">              <span class="keyword">del</span> classification_loss</span><br><span class="line">              <span class="keyword">del</span> regression_loss</span><br><span class="line">          <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">              <span class="built_in">print</span>(e)</span><br><span class="line">              <span class="keyword">continue</span></span><br></pre></td></tr></table></figure>
<p>这里引入了model类。直接看<code>model.py</code></p>
<h1><span id="2-model">2 Model</span></h1><p><img src="https://rin777-1306176007.cos.ap-nanjing.myqcloud.com/20231102012153.png" alt="image.png"><br>大致定义了这个几个类。其实就是下图的结构的代码复现。<br>backbone是ResNet50，然后接一个特征金字塔输出到两个loss。<br><img src="https://rin777-1306176007.cos.ap-nanjing.myqcloud.com/20231102012602.png" alt="image.png"></p>
<h2><span id="21-resnet">2.1 ResNet</span></h2><h3><span id="211-基本架构">2.1.1 基本架构</span></h3><p>下面的resnet我们只看50。<br>首先定义了Resnet50的基础参数。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet50</span>(<span class="params">num_classes, pretrained=<span class="literal">False</span>, **kwargs</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Constructs a ResNet-50 model.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = ResNet(num_classes, Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], **kwargs)</span><br><span class="line">    <span class="comment">#设定resnet50的具体参数</span></span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        model.load_state_dict(model_zoo.load_url(model_urls[<span class="string">&#x27;resnet50&#x27;</span>], model_dir=<span class="string">&#x27;.&#x27;</span>), strict=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure></p>
<p>Resnet的核心就是Shortcut connection，即卷积层之间并不是仅仅线性地连接，还有“跳”的动作。就比如这里直接跳过下一层，将特征输入到下下层了。但有时卷积以后特征通道数不同，没法直接输入进去，所以就有了resnet的下采样。具体后文再介绍。</p>
<p><img src="https://rin777-1306176007.cos.ap-nanjing.myqcloud.com/20231102022432.png" alt="image.png"><br>然后直接看resnet网络的代码。<br>当然这里肯定不是原resnet论文里的代码，而是根据目标检测的任务进行了优化。</p>
<p><img src="https://rin777-1306176007.cos.ap-nanjing.myqcloud.com/20231102013046.png" alt="image.png"></p>
<p><code>__init__</code>定义了基本的网络结构。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_classes, block, layers</span>):</span></span><br><span class="line">    self.inplanes = <span class="number">64</span></span><br><span class="line">    <span class="comment">#输入通道数64</span></span><br><span class="line">    <span class="built_in">super</span>(ResNet, self).__init__()</span><br><span class="line">    <span class="comment">#直接执行初始化</span></span><br><span class="line">    self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">    <span class="comment">#first conv layer，3 input rgb channels，64 output feature channels。</span></span><br><span class="line">    self.bn1 = nn.BatchNorm2d(<span class="number">64</span>)</span><br><span class="line">    <span class="comment">#Batch normalization layer for the output of conv1.</span></span><br><span class="line">    self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment">#ReLU activation function.</span></span><br><span class="line">    self.maxpool = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">    <span class="comment">#汇聚</span></span><br><span class="line">    <span class="comment">#以上部分非常常规地提取输入图片的特征，64个channel。长宽对半砍两次（第一层cov层和池化层）</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#resnet50使用Bottleneck作为基本的残差块，其具体代码定义在retinanet.utils中</span></span><br><span class="line">    <span class="comment">#layer1-4 由若干残差块组成，具体的数量则由后面的resnet深度选择，例如resnet50则对应 [3, 4, 6, 3]。</span></span><br><span class="line">    self.layer1 = self._make_layer(block, <span class="number">64</span>, layers[<span class="number">0</span>])</span><br><span class="line">    <span class="comment">#layer1，input 64 output 256，3 block</span></span><br><span class="line">    self.layer2 = self._make_layer(block, <span class="number">128</span>, layers[<span class="number">1</span>], stride=<span class="number">2</span>)</span><br><span class="line">    <span class="comment">#layer1，input 128 output 512 ,4 block</span></span><br><span class="line">    self.layer3 = self._make_layer(block, <span class="number">256</span>, layers[<span class="number">2</span>], stride=<span class="number">2</span>)</span><br><span class="line">    <span class="comment">#layer3,input 256 output 1028,6 block</span></span><br><span class="line">    self.layer4 = self._make_layer(block, <span class="number">512</span>, layers[<span class="number">3</span>], stride=<span class="number">2</span>)</span><br><span class="line">    <span class="comment">#layer4,input 512 output 2048,3 block</span></span><br></pre></td></tr></table></figure>
<p>下图中，左图basic block，右图为bottleneck，resnet50用的就是bottleneck。<br><img src="https://rin777-1306176007.cos.ap-nanjing.myqcloud.com/20231102022122.png" alt="image.png"></p>
<p>也就是一个block又包含三个卷积层。<br><img src="https://rin777-1306176007.cos.ap-nanjing.myqcloud.com/20231102025658.png" alt="image.png"></p>
<p>整体resnet50的架构<br><img src="https://rin777-1306176007.cos.ap-nanjing.myqcloud.com/20231102023958.png" alt="image.png"></p>
<h3><span id="212-特征channel变化">2.1.2 特征channel变化</span></h3><p>原图经过抽特征得到64 channels。输入layer1 的block1.<br><img src="https://rin777-1306176007.cos.ap-nanjing.myqcloud.com/20231102025923.png" alt="image.png"></p>
<p><img src="https://rin777-1306176007.cos.ap-nanjing.myqcloud.com/20231102025859.png" alt="image.png"></p>
<p>layer1的基准输入数为64，就是说layer1的任何block的输入都是64 channel。<br>block1的输出channel直接从64乘以4变成256是因为conv3的输出乘以了基准数乘4。<br>block1接block2，这里就特征不匹配了。于是block2的conv的1x1卷积能将256的channel又压缩到64。<br>于是就闭环了，理论上可以添加无限多个block但不出问题。<br>但是这里还忽略了resent的一个重要元素就是identity与out相加。<br><img src="https://rin777-1306176007.cos.ap-nanjing.myqcloud.com/20231102034047.png" alt="image.png"><br><img src="https://rin777-1306176007.cos.ap-nanjing.myqcloud.com/20231102034157.png" alt="image.png"><br>之前说到L1，B1的输入是64，输出是256，维度不同不能直接相加，所以需要下采样将其调整到256。后面的b2b3，由于本身输入维度就是256，因此相加时就不需要下采样调整了，但是加还是继续加。所以一般的网络结构图上每个block都会有那根虚线，但不是没条虚线都代表进行了下采样。<br>后面的就很好理解了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_make_layer</span>(<span class="params">self, block, planes, blocks, stride=<span class="number">1</span></span>):</span></span><br><span class="line">    downsample = <span class="literal">None</span></span><br><span class="line">    <span class="comment">#对resnet50， block.expansion = 4</span></span><br><span class="line">    <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> self.inplanes != planes * block.expansion:</span><br><span class="line">        downsample = nn.Sequential(</span><br><span class="line">            nn.Conv2d(self.inplanes, planes * block.expansion,</span><br><span class="line">                      kernel_size=<span class="number">1</span>, stride=stride, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(planes * block.expansion),</span><br><span class="line">        )</span><br><span class="line">    <span class="comment">#由于b1的输入与输出不同，因此需要进行下采样才能够相加，下采样基本就是将feature channel调整到输出的数量。</span></span><br><span class="line">    layers = [block(self.inplanes, planes, stride, downsample)]</span><br><span class="line">    <span class="comment">#layer1时stride均为1.</span></span><br><span class="line">    <span class="comment">#设置stride=2，减小特征图尺寸</span></span><br><span class="line">    self.inplanes = planes * block.expansion</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, blocks):</span><br><span class="line">        layers.append(block(self.inplanes, planes))</span><br><span class="line">    <span class="comment">#这里stride为1，尺寸不变。</span></span><br><span class="line">    <span class="comment">#需要多少个block就加多少个block进layer</span></span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*layers)</span><br></pre></td></tr></table></figure>
<p>以下是layer1的图示。</p>
<p><img src="https://rin777-1306176007.cos.ap-nanjing.myqcloud.com/Res50-L1.png" alt="Res50-L1.png"></p>
<h3><span id="213-extra原理">2.1.3 extra：原理</span></h3><p>虽然清不清楚原理好像不影响代码分析，但是还是记录一下。<br>比较简单的说法是，对于传统的卷积网络，只是一味添加层只会导致结果更差。因为对于非嵌套函数，网络更复杂只会使得其函数越加偏离真实函数。<br>所以为了避免这一点，只要保证新加层之后的模型和原模型同样有效就好了。也就是只能更有效或者相同，但不能更差。<br>但是仅仅想让模型对于输入x输出完全相同的H(x)，模型基本无法训练，所以作者提出残差映射，即学习<code>H(x)-x</code>，这个步骤会比直接学习恒等映射更容易。<br>转化一下就是<code>H(x) = F(x) + x</code><br>于是就有了resnet的shortcut connection。直接将原本的参数与新的卷积层相加。保证了原本的结果的同时拓宽了网络的深度。</p>
<h2><span id="22-fpn">2.2 FPN</span></h2><p>特征金字塔。又是不同于resnet的另一种架构。<br>首先看设置宏观参数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fpn_sizes = [self.layer2[layers[<span class="number">1</span>] - <span class="number">1</span>].conv3.out_channels, self.layer3[layers[<span class="number">2</span>] - <span class="number">1</span>].conv3.out_channels,self.layer4[layers[<span class="number">3</span>] - <span class="number">1</span>].conv3.out_channels]</span><br><span class="line">self.fpn = PyramidFeatures(fpn_sizes[<span class="number">0</span>], fpn_sizes[<span class="number">1</span>], fpn_sizes[<span class="number">2</span>])</span><br></pre></td></tr></table></figure></p>
<p>大致逻辑还是根据resnet选择一些构建模型的参数，但具体为什么这么选，模型怎么构建还不知道。<br>‘还是搬出这张图。</p>
<p><img src="https://rin777-1306176007.cos.ap-nanjing.myqcloud.com/20231102012602.png" alt="image.png"></p>
<p>其中主要包括三个部分：<br>bottom-up，top-down和lateral connection。<br><img src="https://rin777-1306176007.cos.ap-nanjing.myqcloud.com/20231102191656.png" alt="image.png"></p>
<h3><span id="221-bottom-up">2.2.1 bottom-up</span></h3><p>其实就是图片特征抽取的过程。用resnet50举例<br><img src="https://rin777-1306176007.cos.ap-nanjing.myqcloud.com/20231102192914.png" alt="image.png"><br>可以看到经过几次layer，图片的尺寸不断减小。每层正是输出了不同尺度的特征图。这个过程就是bottom-up</p>
<h3><span id="222-top-down">2.2.2 top-down</span></h3><p>主要的过程是将高层得到的feature-map上采样后向下传递。<br>这样高层丰富的语义信息能够传播到低层特征上。</p>
<h3><span id="223lateral-connection">### 2.2.3<strong>Lateral connection</strong></span></h3><p><img src="https://rin777-1306176007.cos.ap-nanjing.myqcloud.com/v2-066baa36f4824bd7fea639d9dd636e89_720w.webp" alt><br>首先卷积层输出放进1x1conv，降低维度后直接与上一层的特征图相加。结果再放进3x3conv中，消除上采样产生的混叠效果。</p>
<h2><span id="23-regressionmodel">2.3 RegressionModel</span></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RegressionModel</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_features_in, num_anchors=<span class="number">9</span>, feature_size=<span class="number">256</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(RegressionModel, self).__init__()</span><br><span class="line">		<span class="comment">#四个相同的卷积层，第一层把feature压缩到256，然后保持不变。（不过这里输入feature本来就是256）</span></span><br><span class="line">        self.conv1 = nn.Conv2d(num_features_in, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act1 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv2 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act2 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv3 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act3 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv4 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act4 = nn.ReLU()</span><br><span class="line">		<span class="comment">#提取特征，输出channel数为num_anchors * 4。</span></span><br><span class="line">        self.output = nn.Conv2d(feature_size, num_anchors * <span class="number">4</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.act1(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.act2(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv3(out)</span><br><span class="line">        out = self.act3(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv4(out)</span><br><span class="line">        out = self.act4(out)</span><br><span class="line"></span><br><span class="line">        out = self.output(out)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># out is B x C x W x H, with C = 4*num_anchors</span></span><br><span class="line">        out = out.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment">#- Original `out`: [B, C, W, H]</span></span><br><span class="line">		<span class="comment">#- After `permute`: [B, W, H, C]</span></span><br><span class="line">		<span class="comment">#- B: Batch size</span></span><br><span class="line">		<span class="comment">#- C: Channels (which is equal to `4 * num_anchors` due to the bounding box regression for each anchor box)</span></span><br><span class="line">		<span class="comment">#- W: Width of the feature map</span></span><br><span class="line">		<span class="comment">#- H: Height of the feature map</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out.contiguous().view(out.shape[<span class="number">0</span>], -<span class="number">1</span>, <span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<p>regression Model用来预测边缘框与锚框之间的差。每个锚框预测四个offsets（即x, y, width, and height）<br>基本上就是一堆卷积层。</p>
<h2><span id="24-classificationmodel">2.4 ClassificationModel</span></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ClassificationModel</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_features_in, num_anchors=<span class="number">9</span>, num_classes=<span class="number">80</span>, prior=<span class="number">0.01</span>, feature_size=<span class="number">256</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ClassificationModel, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.num_anchors = num_anchors</span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Conv2d(num_features_in, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act1 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv2 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act2 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv3 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act3 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv4 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.act4 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.output = nn.Conv2d(feature_size, num_anchors * num_classes, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.output_act = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.act1(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.act2(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv3(out)</span><br><span class="line">        out = self.act3(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv4(out)</span><br><span class="line">        out = self.act4(out)</span><br><span class="line"></span><br><span class="line">        out = self.output(out)</span><br><span class="line">        out = self.output_act(out)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># out is B x C x W x H, with C = n_classes + n_anchors</span></span><br><span class="line">        out1 = out.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        batch_size, width, height, channels = out1.shape</span><br><span class="line"></span><br><span class="line">        out2 = out1.view(batch_size, width, height, self.num_anchors, self.num_classes)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out2.contiguous().view(x.shape[<span class="number">0</span>], -<span class="number">1</span>, self.num_classes)</span><br></pre></td></tr></table></figure>
<p>上一个regression是最后一层每个锚框坐标生成一个预测，这里是每个类生成一个预测。</p>
<h2><span id="25-anchors">2.5 anchors</span></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, image</span>):</span></span><br><span class="line">    </span><br><span class="line">    image_shape = image.shape[<span class="number">2</span>:]</span><br><span class="line">    image_shape = np.array(image_shape)</span><br><span class="line">    image_shapes = [(image_shape + <span class="number">2</span> ** x - <span class="number">1</span>) // (<span class="number">2</span> ** x) <span class="keyword">for</span> x <span class="keyword">in</span> self.pyramid_levels]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute anchors over all pyramid levels</span></span><br><span class="line">    all_anchors = np.zeros((<span class="number">0</span>, <span class="number">4</span>)).astype(np.float32)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> idx, p <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.pyramid_levels):</span><br><span class="line">        anchors         = generate_anchors(base_size=self.sizes[idx], ratios=self.ratios, scales=self.scales)</span><br><span class="line">        shifted_anchors = shift(image_shapes[idx], self.strides[idx], anchors)</span><br><span class="line">        all_anchors     = np.append(all_anchors, shifted_anchors, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    all_anchors = np.expand_dims(all_anchors, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        <span class="keyword">return</span> torch.from_numpy(all_anchors.astype(np.float32)).cuda()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> torch.from_numpy(all_anchors.astype(np.float32))</span><br></pre></td></tr></table></figure>
<p>更具体的暂时不看，总之就是根据输入的图片生成锚框的坐标。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_anchors</span>(<span class="params">base_size=<span class="number">16</span>, ratios=<span class="literal">None</span>, scales=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Generate anchor (reference) windows by enumerating aspect ratios X</span></span><br><span class="line"><span class="string">    scales w.r.t. a reference window.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ratios <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        ratios = np.array([<span class="number">0.5</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> scales <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        scales = np.array([<span class="number">2</span> ** <span class="number">0</span>, <span class="number">2</span> ** (<span class="number">1.0</span> / <span class="number">3.0</span>), <span class="number">2</span> ** (<span class="number">2.0</span> / <span class="number">3.0</span>)])</span><br><span class="line"></span><br><span class="line">    num_anchors = <span class="built_in">len</span>(ratios) * <span class="built_in">len</span>(scales)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># initialize output anchors</span></span><br><span class="line">    anchors = np.zeros((num_anchors, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># scale base_size</span></span><br><span class="line">    anchors[:, <span class="number">2</span>:] = base_size * np.tile(scales, (<span class="number">2</span>, <span class="built_in">len</span>(ratios))).T</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute areas of anchors</span></span><br><span class="line">    areas = anchors[:, <span class="number">2</span>] * anchors[:, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># correct for ratios</span></span><br><span class="line">    anchors[:, <span class="number">2</span>] = np.sqrt(areas / np.repeat(ratios, <span class="built_in">len</span>(scales)))</span><br><span class="line">    anchors[:, <span class="number">3</span>] = anchors[:, <span class="number">2</span>] * np.repeat(ratios, <span class="built_in">len</span>(scales))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># transform from (x_ctr, y_ctr, w, h) -&gt; (x1, y1, x2, y2)</span></span><br><span class="line">    anchors[:, <span class="number">0</span>::<span class="number">2</span>] -= np.tile(anchors[:, <span class="number">2</span>] * <span class="number">0.5</span>, (<span class="number">2</span>, <span class="number">1</span>)).T</span><br><span class="line">    anchors[:, <span class="number">1</span>::<span class="number">2</span>] -= np.tile(anchors[:, <span class="number">3</span>] * <span class="number">0.5</span>, (<span class="number">2</span>, <span class="number">1</span>)).T</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> anchors</span><br></pre></td></tr></table></figure>
<p>下面还有一个shift，就是因为fpn会压缩尺寸，所以锚框也要跟着压缩。</p>
<h2><span id="26-focal-loss">2.6 Focal loss</span></h2><p>整体就两块。<br><img src="https://rin777-1306176007.cos.ap-nanjing.myqcloud.com/20231102213406.png" alt="image.png"></p>
<p>首先还是要熟悉一下focal loss的数学原理。<br><img src="https://rin777-1306176007.cos.ap-nanjing.myqcloud.com/20231102223318.png" alt="image.png"><br>这张图可以看到，在ground truth值差不多的情况下，交叉熵loss高于FL，因此交叉熵loss还希望继续减小，但FL已经基本保持不变了。这就说明FL对分类的准确信并不那么看重，但却有效地避免了过拟合。</p>
<p><img src="https://ask.qcloudimg.com/http-save/7570458/k0quh9ig3v.png" alt></p>
<p>结合上图，$\gamma$越大，<code>well-classified examples</code>的loss就越小，模型就越能专注于难分类的类。<br>$\alpha$则代表类别的权重。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FocalLoss</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="comment">#def __init__(self):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, classifications, regressions, anchors, annotations</span>):</span></span><br><span class="line">        alpha = <span class="number">0.25</span></span><br><span class="line">        gamma = <span class="number">2.0</span></span><br><span class="line">        <span class="comment">#在这里设置alpha和gamma的值</span></span><br><span class="line">        batch_size = classifications.shape[<span class="number">0</span>]</span><br><span class="line">        classification_losses = []</span><br><span class="line">        regression_losses = []</span><br><span class="line"></span><br><span class="line">        anchor = anchors[<span class="number">0</span>, :, :]</span><br><span class="line"></span><br><span class="line">        anchor_widths  = anchor[:, <span class="number">2</span>] - anchor[:, <span class="number">0</span>]</span><br><span class="line">        anchor_heights = anchor[:, <span class="number">3</span>] - anchor[:, <span class="number">1</span>]</span><br><span class="line">        anchor_ctr_x   = anchor[:, <span class="number">0</span>] + <span class="number">0.5</span> * anchor_widths</span><br><span class="line">        anchor_ctr_y   = anchor[:, <span class="number">1</span>] + <span class="number">0.5</span> * anchor_heights</span><br><span class="line">        <span class="comment">#获取anchor的坐标</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(batch_size):</span><br><span class="line"></span><br><span class="line">            classification = classifications[j, :, :]</span><br><span class="line">            regression = regressions[j, :, :]</span><br><span class="line"></span><br><span class="line">            bbox_annotation = annotations[j, :, :]</span><br><span class="line">            bbox_annotation = bbox_annotation[bbox_annotation[:, <span class="number">4</span>] != -<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">            classification = torch.clamp(classification, <span class="number">1e-4</span>, <span class="number">1.0</span> - <span class="number">1e-4</span>)</span><br><span class="line">            <span class="comment">#如果一个img没有label，则只计算cls loss不计算rg loss（因为没有bounding box）</span></span><br><span class="line">            <span class="keyword">if</span> bbox_annotation.shape[<span class="number">0</span>] == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">                    alpha_factor = torch.ones(classification.shape).cuda() * alpha</span><br><span class="line">                    <span class="comment">#生成一堆和cls形状相同的alpha</span></span><br><span class="line">                    alpha_factor = <span class="number">1.</span> - alpha_factor <span class="comment">#（ （1-alpha））</span></span><br><span class="line">                    focal_weight = classification</span><br><span class="line">                    focal_weight = alpha_factor * torch.<span class="built_in">pow</span>(focal_weight, gamma)</span><br><span class="line">                    <span class="comment">#（1-pt)^(gamma)</span></span><br><span class="line"></span><br><span class="line">                    bce = -(torch.log(<span class="number">1.0</span> - classification))</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># cls_loss = focal_weight * torch.pow(bce, gamma)</span></span><br><span class="line">                    cls_loss = focal_weight * bce</span><br><span class="line">                    classification_losses.append(cls_loss.<span class="built_in">sum</span>())</span><br><span class="line">                    regression_losses.append(torch.tensor(<span class="number">0</span>).<span class="built_in">float</span>().cuda())</span><br><span class="line"></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    alpha_factor = torch.ones(classification.shape) * alpha</span><br><span class="line"></span><br><span class="line">                    alpha_factor = <span class="number">1.</span> - alpha_factor</span><br><span class="line">                    focal_weight = classification</span><br><span class="line">                    focal_weight = alpha_factor * torch.<span class="built_in">pow</span>(focal_weight, gamma)</span><br><span class="line"></span><br><span class="line">                    bce = -(torch.log(<span class="number">1.0</span> - classification))</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># cls_loss = focal_weight * torch.pow(bce, gamma)</span></span><br><span class="line">                    cls_loss = focal_weight * bce</span><br><span class="line">                    classification_losses.append(cls_loss.<span class="built_in">sum</span>())</span><br><span class="line">                    regression_losses.append(torch.tensor(<span class="number">0</span>).<span class="built_in">float</span>())</span><br><span class="line"></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            IoU = calc_iou(anchors[<span class="number">0</span>, :, :], bbox_annotation[:, :<span class="number">4</span>]) <span class="comment"># num_anchors x num_annotations</span></span><br><span class="line">            <span class="comment">#计算anchor box和bounding box的IoU</span></span><br><span class="line">            IoU_max, IoU_argmax = torch.<span class="built_in">max</span>(IoU, dim=<span class="number">1</span>) <span class="comment"># num_anchors x 1</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># compute the loss for classification</span></span><br><span class="line">            targets = torch.ones(classification.shape) * -<span class="number">1</span></span><br><span class="line">            <span class="comment">#初始化target值为-1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">                targets = targets.cuda()</span><br><span class="line"></span><br><span class="line">            targets[torch.lt(IoU_max, <span class="number">0.4</span>), :] = <span class="number">0</span></span><br><span class="line">            <span class="comment">#将所有IoU小于0.4的样本设为false</span></span><br><span class="line"></span><br><span class="line">            positive_indices = torch.ge(IoU_max, <span class="number">0.5</span>)</span><br><span class="line">            <span class="comment">#IoU大于0.5则认为是正样本</span></span><br><span class="line">            num_positive_anchors = positive_indices.<span class="built_in">sum</span>()</span><br><span class="line">            <span class="comment">#统计所欲正样本数量</span></span><br><span class="line">            assigned_annotations = bbox_annotation[IoU_argmax, :]</span><br><span class="line">            <span class="comment">#并拿到剩余样本的标注</span></span><br><span class="line">            targets[positive_indices, :] = <span class="number">0</span></span><br><span class="line">            <span class="comment">#初始化，负样本还是-1</span></span><br><span class="line">            targets[positive_indices, assigned_annotations[positive_indices, <span class="number">4</span>].long()] = <span class="number">1</span></span><br><span class="line">            <span class="comment">#对于所有正样本，将预测值与label相同的设为1.</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># After this block of code, the targets tensor will have:</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># -1 for anchors that need to be ignored.</span></span><br><span class="line">            <span class="comment"># 0 for anchors that are background or negative.</span></span><br><span class="line">            <span class="comment"># 1 at the index corresponding to the class of the object for anchors that are positive.</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">                alpha_factor = torch.ones(targets.shape).cuda() * alpha</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                alpha_factor = torch.ones(targets.shape) * alpha</span><br><span class="line"></span><br><span class="line">            alpha_factor = torch.where(torch.eq(targets, <span class="number">1.</span>), alpha_factor, <span class="number">1.</span> - alpha_factor)</span><br><span class="line">            focal_weight = torch.where(torch.eq(targets, <span class="number">1.</span>), <span class="number">1.</span> - classification, classification)</span><br><span class="line">            focal_weight = alpha_factor * torch.<span class="built_in">pow</span>(focal_weight, gamma)</span><br><span class="line"></span><br><span class="line">            bce = -(targets * torch.log(classification) + (<span class="number">1.0</span> - targets) * torch.log(<span class="number">1.0</span> - classification))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># cls_loss = focal_weight * torch.pow(bce, gamma)</span></span><br><span class="line">            cls_loss = focal_weight * bce</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">                cls_loss = torch.where(torch.ne(targets, -<span class="number">1.0</span>), cls_loss, torch.zeros(cls_loss.shape).cuda())</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                cls_loss = torch.where(torch.ne(targets, -<span class="number">1.0</span>), cls_loss, torch.zeros(cls_loss.shape))</span><br><span class="line"></span><br><span class="line">            classification_losses.append(cls_loss.<span class="built_in">sum</span>()/torch.clamp(num_positive_anchors.<span class="built_in">float</span>(), <span class="built_in">min</span>=<span class="number">1.0</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h1><span id="r">R</span></h1><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/62604038"># 【目标检测】FPN(Feature Pyramid Network)</a><br><a target="_blank" rel="noopener" href="https://medium.com/@rossleecooloh/%E7%9B%B4%E8%A7%80%E7%90%86%E8%A7%A3resnet-%E7%B0%A1%E4%BB%8B-%E8%A7%80%E5%BF%B5%E5%8F%8A%E5%AF%A6%E4%BD%9C-python-keras-8d1e2e057de2"># 直觀理解ResNet —簡介、 觀念及實作(Python Keras)</a><br><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1669261">## 10分钟理解Focal loss数学原理与Pytorch代码（翻译）</a></p>

            <div class="clearfix"></div>
            <hr class="nogutter">
        </div>
        <nav class="m-pagination col-md-8 col-md-offset-2 col-sm-24" role="pagination">
    
    
    <a class="pull-right" href="../../../10/30/ml_%E7%AE%80%E5%8D%95%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/">
        简单的数据处理 →
    </a>
    
</nav>

        <div class="col-md-8 col-md-offset-2 col-sm-24"><script type="text/javascript">
  /**
   * 搜狐畅言
   */

  /*
  document.write('<div id="SOHUCS" sid="' + window.location.pathname.slice(1) + '" ></div>');

  window.onload = function () {
    (function () {
      var appid = 'cytXXXX';
      var conf = 'prod_xxxxxxxxxxxxxxxxx';
      var width = window.innerWidth || document.documentElement.clientWidth;
      var loadJs = function (d, a, id) {
        var c = document.getElementsByTagName("head")[0] || document.head || document.documentElement;
        var b = document.createElement("script");
        b.setAttribute("type", "text/javascript");
        b.setAttribute("charset", "UTF-8");
        b.setAttribute("src", d);
        if (id) {
          b.setAttribute("id", id);
        }
        if (typeof a === "function") {
          if (window.attachEvent) {
            b.onreadystatechange = function () {
              var e = b.readyState;
              if (e === "loaded" || e === "complete") {
                b.onreadystatechange = null;
                a()
              }
            }
          } else {
            b.onload = a
          }
        }
        c.appendChild(b)
      };

      loadJs("https://changyan.sohu.com/upload/changyan.js", function () {
        window.changyan.api.config({
          appid: appid,
          conf: conf
        })
      });
    })();
  }
  */

</script>
</div>
    </div>
</section>

<!-- Highlight.js -->

<link rel="stylesheet"
href="//highlightjs.org/static/demo/styles/atom-one-light.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js">
</script>
<script>
hljs.initHighlightingOnLoad();

</script>


      
<!-- ============================ Footer =========================== -->

<footer>
    <div class="container">
            <div class="copy">
                <p>
                    &copy; 2014<script>new Date().getFullYear()>2010&&document.write("-"+new Date().getFullYear());</script>, Content By Rin777. All Rights Reserved.
                </p>
                <p>Theme By <a target="_blank" rel="noopener" href="//go.kieran.top" style="color: #767D84">Kieran</a></p>
            </div>
            <div class="social">
                <ul>
                    
                    <li><a href="https://github.com/" title="Github" target="_blank"><i class="icon-github"></i></a>&nbsp;</li>
                    
                    
                    
                    
                    
                </ul>
            </div>
            <div class="clearfix"> </div>
        </div>
</footer>

<!-- ============================ END Footer =========================== -->
      <!-- Load our scripts -->
<!-- Resizable 'on-demand' full-height hero -->
<script type="text/javascript">
    var resizeHero = function () {
        var hero = $(".cover,.heightblock"),
            window1 = $(window);
        hero.css({
            "height": window1.height()
        });
    };

    resizeHero();

    $(window).resize(function () {
        resizeHero();
    });
</script>
<script src="/js/plugins.min.js"></script><!-- Bootstrap core and concatenated plugins always load here -->
<script src="/js/scripts.js"></script><!-- Theme scripts -->


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$('#intro').find('img').each(function(){
  var alt = this.alt;

  if (alt){
    $(this).after('<span class="caption" style="display:none">' + alt + '</span>');
  }

  $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox" rel="gallery" />');
});
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



      
            <style>
.local-search-popup {
  display: none;
  position: fixed;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  padding: 0;
  background: rgba(255, 255, 255, .9);
  color: #333;
  z-index: 9999;
  border-radius: 5px;
  overflow: scroll;
}
#local-search-input {
  width: 100%;
  border: none;
  outline: none;
  border-bottom: 1px solid #151515;
  background-color: initial;
}
.search-result-list {
  list-style: none;
  padding-left: 0;
}
.search-result-list > li {
  margin-top: 15px;
  border-bottom: 1px solid #ddd;
  transition: all ease .3s;
}
.search-result-list > li:hover {
  border-bottom: 1px solid gray;
}
.search-result-title {
  font-size: 16px;
}
.search-result {
  line-height: 20px;
}
.search-keyword {
  font-weight: normal;
  color: #c00;
}

@media (min-width: 890px) {
  .popup-btn-close {
    position: absolute;
    top: 15px;
    left: 35px;
    border: 1px solid #151515;
    padding: 0px 10px;
    border-top-left-radius: 8px;
    cursor: pointer;
    transition: all ease .3s;
  }
  .popup-btn-close:hover {
    background: #151515;
    opacity: .9;
    color: #fff;
  }
}
@media (max-width: 890px) {
  .popup-btn-close {
    font-size: 0;
    position: fixed;
    right: 20px;
    bottom: 50px;
    width: 50px;
    height: 50px;
    background: #fff;
    border-radius: 50%;
    box-shadow: 1px 1px 5px #888;
    cursor: pointer;
  }
  .popup-btn-close::after {
    content: '←';
    color: #151515;
    position: absolute;
    top: 0;
    left: 0;
    font-size: 20px;
    width: 100%;
    height: 100%;
    line-height: 50px;
    text-align: center;
  }
}
</style>

<div class="popup search-popup local-search-popup">
  <span class="popup-btn-close">
    ESC
  </span>
  <div class="container">
    <div class="col-md-8 col-md-offset-2">
      <div class="local-search-header clearfix">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="local-search-input-wrapper">
          <input autocomplete="off" placeholder="Search..." type="text" id="local-search-input">
        </div>
      </div>
      <div id="local-search-result"></div>
    </div>
  </div>
</div>

<script src="/js/ziploader.js"></script>


  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.json";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').fadeOut(300);
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $('.popup').fadeIn(300);
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // get search zip version
    $.get('/searchVersion.txt?t=' + (+new Date()), function(res) {
      if (localStorage.getItem('searchVersion') !== res) {
        localStorage.setItem('searchVersion', res);
        initSearchJson();
      }
    });

    function initSearchJson () {
      initLoad(['/search.zip'], {
        loadOptions: {
          success: function(obj) {
            localStorage.setItem('searchJson', obj['search.json'])
          },
          error: function(e) {
            return console.log(e)
          }
        },
        returnOptions: {
          'json': TYPE_TEXT
        },
        mimeOptions:{
          'json':'application/json'
        }
      })
    }


    // search function;
    var searchFunc = function(search_id, content_id) {
      'use strict';

      isfetched = true;
      var datas = JSON.parse(localStorage.getItem('searchJson'));
      console.log(search_id)
      var input = document.getElementById(search_id);
      var resultContent = document.getElementById(content_id);
      var inputEventFunction = function() {
        var searchText = input.value.trim().toLowerCase();
        var keywords = searchText.split(/[\s\-]+/);
        if (keywords.length > 1) {
          keywords.push(searchText);
        }
        var resultItems = [];
        if (searchText.length > 0) {
          // perform local searching
          datas.forEach(function(data) {
            var isMatch = false;
            var hitCount = 0;
            var searchTextCount = 0;
            var title = data.title ? data.title.trim() : '';
            var titleInLowerCase = title.toLowerCase();
            var content = data.content ? data.content.trim().replace(/<[^>]+>/g,"") : '';
            var contentInLowerCase = content.toLowerCase();
            var articleUrl = decodeURIComponent(data.url);
            var indexOfTitle = [];
            var indexOfContent = [];
            // only match articles with not empty titles
            keywords.forEach(function(keyword) {
              function getIndexByWord(word, text, caseSensitive) {
                var wordLen = word.length;
                if (wordLen === 0) {
                  return [];
                }
                var startPosition = 0, position = [], index = [];
                if (!caseSensitive) {
                  text = text.toLowerCase();
                  word = word.toLowerCase();
                }
                while ((position = text.indexOf(word, startPosition)) > -1) {
                  index.push({position: position, word: word});
                  startPosition = position + wordLen;
                }
                return index;
              }

              indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
              indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
            });
            if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
              isMatch = true;
              hitCount = indexOfTitle.length + indexOfContent.length;
            }

            // show search results

            if (isMatch) {
              // sort index by position of keyword

              [indexOfTitle, indexOfContent].forEach(function (index) {
                index.sort(function (itemLeft, itemRight) {
                  if (itemRight.position !== itemLeft.position) {
                    return itemRight.position - itemLeft.position;
                  } else {
                    return itemLeft.word.length - itemRight.word.length;
                  }
                });
              });

              // merge hits into slices

              function mergeIntoSlice(text, start, end, index) {
                var item = index[index.length - 1];
                var position = item.position;
                var word = item.word;
                var hits = [];
                var searchTextCountInSlice = 0;
                while (position + word.length <= end && index.length != 0) {
                  if (word === searchText) {
                    searchTextCountInSlice++;
                  }
                  hits.push({position: position, length: word.length});
                  var wordEnd = position + word.length;

                  // move to next position of hit

                  index.pop();
                  while (index.length != 0) {
                    item = index[index.length - 1];
                    position = item.position;
                    word = item.word;
                    if (wordEnd > position) {
                      index.pop();
                    } else {
                      break;
                    }
                  }
                }
                searchTextCount += searchTextCountInSlice;
                return {
                  hits: hits,
                  start: start,
                  end: end,
                  searchTextCount: searchTextCountInSlice
                };
              }

              var slicesOfTitle = [];
              if (indexOfTitle.length != 0) {
                slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
              }

              var slicesOfContent = [];
              while (indexOfContent.length != 0) {
                var item = indexOfContent[indexOfContent.length - 1];
                var position = item.position;
                var word = item.word;
                // cut out 100 characters
                var start = position - 20;
                var end = position + 80;
                if(start < 0){
                  start = 0;
                }
                if (end < position + word.length) {
                  end = position + word.length;
                }
                if(end > content.length){
                  end = content.length;
                }
                slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
              }

              // sort slices in content by search text's count and hits' count

              slicesOfContent.sort(function (sliceLeft, sliceRight) {
                if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                  return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                  return sliceRight.hits.length - sliceLeft.hits.length;
                } else {
                  return sliceLeft.start - sliceRight.start;
                }
              });

              // select top N slices in content

              var upperBound = parseInt('2');
              if (upperBound >= 0) {
                slicesOfContent = slicesOfContent.slice(0, upperBound);
              }

              // highlight title and content

              function highlightKeyword(text, slice) {
                var result = '';
                var prevEnd = slice.start;
                slice.hits.forEach(function (hit) {
                  result += text.substring(prevEnd, hit.position);
                  var end = hit.position + hit.length;
                  result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                  prevEnd = end;
                });
                result += text.substring(prevEnd, slice.end);
                return result;
              }

              var resultItem = '';

              if (slicesOfTitle.length != 0) {
                resultItem += "<li><a target='_blank' href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
              } else {
                resultItem += "<li><a target='_blank' href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
              }

              slicesOfContent.forEach(function (slice) {
                resultItem += "<a target='_blank' href='" + articleUrl + "'>" +
                  "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                  "...</p>" + "</a>";
              });

              resultItem += "</li>";
              resultItems.push({
                item: resultItem,
                searchTextCount: searchTextCount,
                hitCount: hitCount,
                id: resultItems.length
              });
            }
          })
        };
        if (keywords.length === 1 && keywords[0] === "") {
          resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
        } else if (resultItems.length === 0) {
          resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
        } else {
          resultItems.sort(function (resultLeft, resultRight) {
            if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
              return resultRight.searchTextCount - resultLeft.searchTextCount;
            } else if (resultLeft.hitCount !== resultRight.hitCount) {
              return resultRight.hitCount - resultLeft.hitCount;
            } else {
              return resultRight.id - resultLeft.id;
            }
          });
          var searchResultList = '<ul class=\"search-result-list\">';
          resultItems.forEach(function (result) {
            searchResultList += result.item;
          })
          searchResultList += "</ul>";
          resultContent.innerHTML = searchResultList;
        }
      }

      if ('auto' === 'auto') {
        input.addEventListener('input', inputEventFunction);
      } else {
        $('.search-icon').click(inputEventFunction);
        input.addEventListener('keypress', function (event) {
          if (event.keyCode === 13) {
            inputEventFunction();
          }
        });
      }

      // remove loading animation
      $('body').css('overflow', '');

      proceedsearch();
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        $('.sb-close').click();
        searchFunc('local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>


      
      

<!--

<link rel="stylesheet" href="/dist/APlayer.min.css">
<div id="aplayer"></div>
<script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script>

<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>
<meting-js
      server="netease"
      type="playlist"
      id="4904272454">
</meting-js>
-->

</body>

</html>







