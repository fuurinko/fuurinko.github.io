<!DOCTYPE html>
<!--[if lte IE 8 ]>
<html class="ie" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-US" lang="en-US">
<![endif]-->
<!--[if (gte IE 9)|!(IE)]><!-->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh-CN" lang="zh-CN">
<!--<![endif]-->

<head>

  <title>04_ Linear Algebra | Rin</title>
  <!-- Meta data -->
    <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" >
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="generator" content="Rin">
    <meta name="author" content="Rin777">
    <meta name="description" content="" />
    <meta name="keywords" content="" />

    <!-- Favicon, (keep icon in root folder) -->
    <link rel="Shortcut Icon" href="/img/favicon.ico" type="image/ico">

    <link rel="alternate" href="/atom.xml" title="Rin" type="application/atom+xml">
    <link rel="stylesheet" href="/css/all.css" media="screen" type="text/css">
    

    <!--[if IE 8]>
    <link rel="stylesheet" type="text/css" href="/css/ie8.css" />
    <![endif]-->

    <!-- jQuery | Load our jQuery, with an alternative source fallback to a local version if request is unavailable -->
    <script src="/js/jquery-1.11.1.min.js"></script>
    <script>window.jQuery || document.write('<script src="js/jquery-1.11.1.min.js"><\/script>')</script>

    <!-- Load these in the <head> for quicker IE8+ load times -->
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="/js/html5shiv.min.js"></script>
    <script src="/js/respond.min.js"></script>
    <![endif]-->

  
  
  

  <style>.col-md-8.col-md-offset-2.opening-statement img{display:none;}</style>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><link rel="stylesheet" href="/css/prism.css" type="text/css"></head>

<!--
<body class="post-template">
-->
<body id="index" class="lightnav animsition">
      <!-- ============================ Off-canvas navigation =========================== -->

    <div class="sb-slidebar sb-right sb-style-overlay sb-momentum-scrolling">
        <div class="sb-close" aria-label="Close Menu" aria-hidden="true">
            <img src="/img/close.png" alt="Close"/>
        </div>
        <!-- Lists in Slidebars -->
        <ul class="sb-menu">
            <li><a href="/" class="animsition-link" title="Home">Home</a></li>
            <li><a href="/archives" class="animsition-link" title="archive">archives</a></li>
            <!-- Dropdown Menu -->
			 
            
        	<li>
        		<a class="sb-toggle-submenu">Categories<span class="sb-caret"></span></a>
            	<ul class="sb-submenu">
				  	
				    <li><a href="/categories/AUDITION/" class="animsition-link">AUDITION<small>(23)</small></a></li>
				    
				    <li><a href="/categories/Binary-security/" class="animsition-link">Binary_security<small>(101)</small></a></li>
				    
				    <li><a href="/categories/CSAPP-LAB/" class="animsition-link">CSAPP LAB<small>(1)</small></a></li>
				    
				    <li><a href="/categories/Linux/" class="animsition-link">Linux<small>(1)</small></a></li>
				    
				    <li><a href="/categories/ML/" class="animsition-link">ML<small>(27)</small></a></li>
				    
				    <li><a href="/categories/PWN-COLLEGE/" class="animsition-link">PWN.COLLEGE<small>(1)</small></a></li>
				    
				</ul>
        	</li>
			
            
            <li>
                <a class="sb-toggle-submenu">Links<span class="sb-caret"></span></a>
                <ul class="sb-submenu">
                    
                    <li><a target="_blank" rel="noopener" href="https://weibo.com/u/1682818607" class="animsition-link">没有营养的推广页</a></li>
                    
                    <li><a target="_blank" rel="noopener" href="http://www.2323bb.ltd" class="animsition-link">cc_sakura</a></li>
                    
                    <li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_36995313" class="animsition-link">F@LLe0</a></li>
                    
                    <li><a target="_blank" rel="noopener" href="https://yyz9.cn" class="animsition-link">YYZ</a></li>
                    
                    <li><a target="_blank" rel="noopener" href="https://www.star123.top" class="animsition-link">star</a></li>
                    
                </ul>
            </li>
            
        </ul>
        <!-- Lists in Slidebars -->
        <ul class="sb-menu secondary">
            
            <li><a href="javascript:;" class="popup-trigger" title="Search"><span class="search-icon"></span>Search</a></li>
            
            <li><a href="/about.html" class="animsition-link" title="about">About</a></li>
            <li><a href="/atom.xml" class="animsition-link" title="rss">RSS</a></li>
        </ul>
    </div>
    
    <!-- ============================ END Off-canvas navigation =========================== -->

    <!-- ============================ #sb-site Main Page Wrapper =========================== -->

    <div id="sb-site">
        <!-- #sb-site - All page content should be contained within this id, except the off-canvas navigation itself -->

        <!-- ============================ Header & Logo bar =========================== -->

        <div id="navigation" class="navbar navbar-fixed-top">
            <div class="navbar-inner">
                <div class="container">
                    <!-- Nav logo -->
                    <div class="logo">
                        <a href="/" title="Logo" class="animsition-link">
                         <img src="https://rin777-1306176007.cos.ap-nanjing.myqcloud.com/IMG_0282.jpg" alt="Logo" width="35px;"/> 
                        </a>
                    </div>
                    <!-- // Nav logo -->
                    <!-- Info-bar -->
                    <nav>
                        <ul class="nav">
                            <li><a href="/" class="animsition-link">Rin</a></li>
                            <li class="nolink"><span>Always </span>Creative.</li>
                            
                            <li><a href="https://github.com/" title="Github" target="_blank"><i class="icon-github"></i></a></li>
                            
                            
                            
                            
                            
                            <li class="nolink"><span>Welcome!</span></li>
                        </ul>
                    </nav>
                    <!--// Info-bar -->
                </div>
                <!-- // .container -->
                <div class="learnmore sb-toggle-right">More</div>
                <button type="button" class="navbar-toggle menu-icon sb-toggle-right" title="More">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar before"></span>
                <span class="icon-bar main"></span>
                <span class="icon-bar after"></span>
                </button>
            </div>
            <!-- // .navbar-inner -->
        </div>

        <!-- ============================ Header & Logo bar =========================== -->


      
<section id="intro">
    <div class="container">
        <div class="row col-md-offset-2">
            <div class="col-md-8">
    			<span class="post-meta">
      <time datetime="2023-03-09T16:00:00.000Z" itemprop="datePublished">
          2023-03-10
      </time>
    
    
    | 
    <a href='/tags/d2l/'>d2l</a>
    
    
</span>
                <h1>04_ Linear Algebra</h1>
            </div>
        </div>
        <div class="col-md-8 col-md-offset-2">
      		<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script>

<h2><span id="41-basic-manipulation-of-linear-algebra">4.1 Basic Manipulation of Linear Algebra</span></h2><h3><span id="411-vector-addition">4.1.1 Vector Addition</span></h3><script type="math/tex; mode=display">
c = a + b</script><p><img src="https://rin777-1306176007.cos.ap-nanjing.myqcloud.com/vector.png" alt="vector"></p>
<h3><span id="412-vector-multiplication">4.1.2 Vector Multiplication</span></h3><script type="math/tex; mode=display">
c = \alpha 
\cdot a</script><p><img src="https://rin777-1306176007.cos.ap-nanjing.myqcloud.com/multiplication.png" alt="multiplication"></p>
<h3><span id="413-metrix-multiplication">4.1.3 Metrix Multiplication</span></h3><h4><span id="4131-abstract-defination">4.1.3.1 Abstract Defination</span></h4><script type="math/tex; mode=display">
{\displaystyle (AB)_{ij}=\sum _{r=1}^{n}a_{ir}b_{rj}=a_{i1}b_{1j}+a_{i2}b_{2j}+\cdots +a_{in}b_{nj}}</script><h4><span id="4132-caculation-mathod">4.1.3.2 Caculation Mathod</span></h4><p>assume metrix A and B,</p>
<script type="math/tex; mode=display">
{  {A}}={\begin{vmatrix}a_11&a_12\\a_21&a_22\end{vmatrix}}</script><script type="math/tex; mode=display">
{  {B}}={\begin{vmatrix}b_11&b_12\\b_21&b_22\end{vmatrix}}</script><p>then,</p>
<p><img src="https://rin777-1306176007.cos.ap-nanjing.myqcloud.com/Screen%20Shot%202023-03-12%20at%209.04.17%20PM.png" alt="Screen Shot 2023-03-12 at 9.04.17 PM"></p>
<p>example:</p>
<script type="math/tex; mode=display">
{\begin{bmatrix}1&0&2\\-1&3&1\end{bmatrix}}\cdot {\begin{bmatrix}3&1\\2&1\\1&0\end{bmatrix}}</script><script type="math/tex; mode=display">
</script><script type="math/tex; mode=display">={\begin{bmatrix}1{\begin{bmatrix}3&1\end{bmatrix}}+0{\begin{bmatrix}2&1\end{bmatrix}}+2{\begin{bmatrix}1&0\end{bmatrix}}\\-1{\begin{bmatrix}3&1\end{bmatrix}}+3{\begin{bmatrix}2&1\end{bmatrix}}+1{\begin{bmatrix}1&0\end{bmatrix}}\end{bmatrix}}</script><script type="math/tex; mode=display">
</script><script type="math/tex; mode=display">={\begin{bmatrix}{\begin{bmatrix}3&1\end{bmatrix}}+{\begin{bmatrix}0&0\end{bmatrix}}+{\begin{bmatrix}2&0\end{bmatrix}}\\{\begin{bmatrix}-3&-1\end{bmatrix}}+{\begin{bmatrix}6&3\end{bmatrix}}+{\begin{bmatrix}1&0\end{bmatrix}}\end{bmatrix}}</script><script type="math/tex; mode=display">
</script><script type="math/tex; mode=display">={\begin{bmatrix}5&1\\4&2\end{bmatrix}}</script><h4><span id="4133-characteristic">4.1.3.3 Characteristic</span></h4><p>1 ) can’t be exchanged (AB $\neq$ BA)</p>
<h3><span id="414-norm">4.1.4 Norm</span></h3><script type="math/tex; mode=display">c = A \cdot b ,\ \ \ \ hence \ \|c\| \ \leqslant \|A\| \cdot \|b\|</script><p>1) metrix norm : the minimun value to satisfy the above formula<br>2) Frobenius Norm : $|A|_{Frob} = \left[ \sum_{ij}A_{ij}^2 \right]^{1/2}$(commonly used)</p>
<h3><span id="415-special-metrix">4.1.5 Special Metrix</span></h3><h4><span id="4151-symmetic-amp-anti-symmectric">4.1.5.1 Symmetic  &amp; Anti-Symmectric</span></h4><h5><span id="symmtric">symmtric</span></h5><script type="math/tex; mode=display">A_{ij} = A_{ji}</script><h5><span id="anti-symmetric">Anti-symmetric</span></h5><script type="math/tex; mode=display">A_{ij} = -A_{ji}</script><h4><span id="4152-positive-definite-matrix">4.1.5.2 Positive-Definite Matrix</span></h4><h4><span id="4154-permutation-matrix">4.1.5.4 Permutation Matrix</span></h4><script type="math/tex; mode=display">
P \ where \ P_{ij} = 1 \ , if \ and \ only \ if \ j = \pi(i)</script><p>1) Permutation Matrix is orthogonal matrix.</p>
<h4><span id="4155-feature-matrix">4.1.5.5 Feature Matrix</span></h4><p>The Matrix which can’t be changed by the multipled matrix</p>
<script type="math/tex; mode=display">
Ax = \lambda x , \ then \ \lambda \ is \ a \  featrue \ matrix</script><h2><span id="42-relization-in-python">4.2  Relization in python</span></h2><h3><span id="421-scalars">4.2.1 Scalars</span></h3><p>Doesn’t have direction ,dimension or other things.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor(<span class="number">3.0</span>)</span><br><span class="line">y = torch.tensor(<span class="number">2.0</span>)</span><br><span class="line"></span><br><span class="line">x + y, x * y, x / y, x**y</span><br><span class="line"><span class="comment"># x**y ==&gt; 3=x^y</span></span><br><span class="line"><span class="comment"># (tensor(5.), tensor(6.), tensor(1.5000), tensor(9.))</span></span><br></pre></td></tr></table></figure></p>
<h3><span id="422-vectors">4.2.2 Vectors</span></h3><p>Consider Vectors as the array of scalars, like a fixed length list of scalars.</p>
<p>Using <code>arrange</code>to generate the tensor vector.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = torch.arange(<span class="number">3</span>)</span><br><span class="line">x</span><br><span class="line"><span class="comment">#tensor([0, 1, 2])</span></span><br></pre></td></tr></table></figure></p>
<p>We can visualize vectors by stacking their elements vertically.</p>
<script type="math/tex; mode=display">
x_{i} = \begin{vmatrix} x_{1} \\ x_{2} \\ x_{3} \\ \dots \\ xi \end{vmatrix}</script><p>using <code>index</code>to access the element in vector<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x[<span class="number">0</span>],<span class="built_in">len</span>(x)</span><br><span class="line"><span class="comment">#(tensor(0), 3)</span></span><br></pre></td></tr></table></figure></p>
<h3><span id="423-matric">4.2.3 Matric</span></h3><p>Using <code>reshape</code> to generate the m x n matrix.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">M = torch.arange(<span class="number">15</span>).reshape(<span class="number">3</span>,<span class="number">5</span>)</span><br><span class="line">M</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[ 0,  1,  2,  3,  4],</span></span><br><span class="line"><span class="string">        [ 5,  6,  7,  8,  9],</span></span><br><span class="line"><span class="string">        [10, 11, 12, 13, 14]])</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h4><span id="4231-matric-transpose">4.2.3.1 Matric transpose</span></h4><p>Exchange the rows with colmuns along the diagonal.</p>
<script type="math/tex; mode=display">B = A ^ T</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">M.T</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[ 0,  5, 10],</span></span><br><span class="line"><span class="string">        [ 1,  6, 11],</span></span><br><span class="line"><span class="string">        [ 2,  7, 12],</span></span><br><span class="line"><span class="string">        [ 3,  8, 13],</span></span><br><span class="line"><span class="string">        [ 4,  9, 14]])</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>For a stmmetric matrix ,the transpose equals to itself.</p>
<h3><span id="424-tensors">4.2.4 Tensors</span></h3><p>Tensors give us a generic way to describe extensions to nth-order arrays.<br>For example ,vector is the promotion of scalar, and matrix is the promotion of the vector,so tensor is a promotion of the matrix,the dimension of the tensor can be enlarged in 3,4,…dimensions,etc.<br>And the rule to create the tensor is from right to left : 4 is scalar. 3 is array ,then 2 is the higer order.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">torch.arange(<span class="number">24</span>).reshape(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2,  3],</span></span><br><span class="line"><span class="string">         [ 4,  5,  6,  7],</span></span><br><span class="line"><span class="string">         [ 8,  9, 10, 11]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[12, 13, 14, 15],</span></span><br><span class="line"><span class="string">         [16, 17, 18, 19],</span></span><br><span class="line"><span class="string">         [20, 21, 22, 23]]])</span></span><br><span class="line"><span class="string">         &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3><span id="425-basic-arithmetic">4.2.5 Basic Arithmetic</span></h3><h4><span id="4251-multiplication-and-addition">4.2.5.1 Multiplication and Addition</span></h4><p>The basic rule of arithmatic operation is simial as the vectors or matrixs.(simple linear addition)</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"> tensor([[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">        [<span class="number">6</span>, <span class="number">7</span>],</span><br><span class="line">        [<span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment">#In [14]:</span></span><br><span class="line">A+b</span><br><span class="line"></span><br><span class="line"><span class="comment">#Out[14]:</span></span><br><span class="line"></span><br><span class="line">tensor([[ <span class="number">0</span>,  <span class="number">2</span>],</span><br><span class="line">        [ <span class="number">4</span>,  <span class="number">6</span>],</span><br><span class="line">        [ <span class="number">8</span>, <span class="number">10</span>],</span><br><span class="line">        [<span class="number">12</span>, <span class="number">14</span>],</span><br><span class="line">        [<span class="number">16</span>, <span class="number">18</span>]])</span><br><span class="line"><span class="comment">#In [15]: </span></span><br><span class="line">A*b <span class="comment">#(Hadamard product)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Out[15]:</span></span><br><span class="line"></span><br><span class="line">tensor([[ <span class="number">0</span>,  <span class="number">1</span>],</span><br><span class="line">        [ <span class="number">4</span>,  <span class="number">9</span>],</span><br><span class="line">        [<span class="number">16</span>, <span class="number">25</span>],</span><br><span class="line">        [<span class="number">36</span>, <span class="number">49</span>],</span><br><span class="line">        [<span class="number">64</span>, <span class="number">81</span>]])</span><br></pre></td></tr></table></figure>
<p>scalar multiply with tensor:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">a = <span class="number">2</span></span><br><span class="line">X = torch.arange(<span class="number">24</span>).reshape(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">a + X, (a * X).shape</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(tensor([[[ 0,  1,  2,  3],</span></span><br><span class="line"><span class="string">          [ 4,  5,  6,  7],</span></span><br><span class="line"><span class="string">          [ 8,  9, 10, 11]],</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">         [[12, 13, 14, 15],</span></span><br><span class="line"><span class="string">          [16, 17, 18, 19],</span></span><br><span class="line"><span class="string">          [20, 21, 22, 23]]]),</span></span><br><span class="line"><span class="string">          </span></span><br><span class="line"><span class="string"> tensor([[[ 2,  3,  4,  5],</span></span><br><span class="line"><span class="string">          [ 6,  7,  8,  9],</span></span><br><span class="line"><span class="string">          [10, 11, 12, 13]],</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">         [[14, 15, 16, 17],</span></span><br><span class="line"><span class="string">          [18, 19, 20, 21],</span></span><br><span class="line"><span class="string">          [22, 23, 24, 25]]]), add 2</span></span><br><span class="line"><span class="string">          </span></span><br><span class="line"><span class="string"> tensor([[[ 0,  2,  4,  6],</span></span><br><span class="line"><span class="string">          [ 8, 10, 12, 14],</span></span><br><span class="line"><span class="string">          [16, 18, 20, 22]],</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">         [[24, 26, 28, 30],</span></span><br><span class="line"><span class="string">          [32, 34, 36, 38],</span></span><br><span class="line"><span class="string">          [40, 42, 44, 46]]])) multiply with 2</span></span><br><span class="line"><span class="string">          &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h4><span id="4252-sum">4.2.5.2 Sum</span></h4><p>using <code>sum()</code>to return the sum value of each elements in a tensor.<br>the returned value, regardless of the shape of the tensor, is always a scalar.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">q = torch.arange(<span class="number">30</span>).reshape(<span class="number">5</span>,<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">qs = q.<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment">#In [23]:</span></span><br><span class="line"></span><br><span class="line">qs</span><br><span class="line"></span><br><span class="line"><span class="comment">#Out[23]:</span></span><br><span class="line"></span><br><span class="line">tensor(<span class="number">435</span>)</span><br></pre></td></tr></table></figure>
<p>otherwise, we can indicate the specific axis to caculate the sum:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">q_1 = q.<span class="built_in">sum</span>(axis = <span class="number">0</span>)</span><br><span class="line">q_2 = q.<span class="built_in">sum</span>(axis = <span class="number">1</span>)</span><br><span class="line">q_3 = q.<span class="built_in">sum</span>(axis = [<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(tensor([60, 65, 70, 75, 80, 85]),tensor([ 15,  51,  87, 123, 159]),tensor(435))&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h4><span id="4253-mean">4.2.5.3 Mean</span></h4><p>Also a scalar, shows the average value of all the element.(Can also specify the axis  )<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">x = torch.arange(<span class="number">3</span>, dtype=torch.float32)</span><br><span class="line">A</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0.,  1.,  2.,  3.,  4.],</span></span><br><span class="line"><span class="string">         [ 5.,  6.,  7.,  8.,  9.]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[10., 11., 12., 13., 14.],</span></span><br><span class="line"><span class="string">         [15., 16., 17., 18., 19.]]])&#x27;&#x27;&#x27;</span></span><br><span class="line">A.mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># tensor(9.5000)</span></span><br><span class="line"></span><br><span class="line">A.<span class="built_in">sum</span>() / A.numel()</span><br><span class="line"><span class="comment">#tensor(9.5000)</span></span><br></pre></td></tr></table></figure></p>
<p>The operation above can be considered as a REDUCTION because both <code>mean</code> and <code>sum</code> will deplete some of the dimension in the tensor.<br>So the function to caculate them without reduction as follows:</p>
<h5><span id="keepdims">keepdims</span></h5><p>Activate this variable we can keep the dimension with a blank value .<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#In [41]:</span></span><br><span class="line">sum_A = A.<span class="built_in">sum</span>(axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">sum_A, sum_A.shape</span><br><span class="line"></span><br><span class="line"><span class="comment">#Out[41]:</span></span><br><span class="line"></span><br><span class="line">(tensor([[[ <span class="number">5.</span>,  <span class="number">7.</span>,  <span class="number">9.</span>, <span class="number">11.</span>, <span class="number">13.</span>]],</span><br><span class="line"> </span><br><span class="line">         [[<span class="number">25.</span>, <span class="number">27.</span>, <span class="number">29.</span>, <span class="number">31.</span>, <span class="number">33.</span>]]]),</span><br><span class="line"> torch.Size([<span class="number">2</span>, <span class="number">1</span>, <span class="number">5</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment">#In [42]:</span></span><br><span class="line"></span><br><span class="line">sum_A = A.<span class="built_in">sum</span>(axis=<span class="number">1</span>, keepdims=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">sum_A, sum_A.shape</span><br><span class="line"></span><br><span class="line"><span class="comment">#Out[42]:</span></span><br><span class="line"></span><br><span class="line">(tensor([[ <span class="number">5.</span>,  <span class="number">7.</span>,  <span class="number">9.</span>, <span class="number">11.</span>, <span class="number">13.</span>],</span><br><span class="line">         [<span class="number">25.</span>, <span class="number">27.</span>, <span class="number">29.</span>, <span class="number">31.</span>, <span class="number">33.</span>]]),</span><br><span class="line"> torch.Size([<span class="number">2</span>, <span class="number">5</span>]))</span><br></pre></td></tr></table></figure></p>
<p> we can divide <code>A</code>by <code>sum_A</code> with broadcasting to create a matrix where each row sums up to 1.<br> (And only when the dimension is equal to the original one ,broasting can work)<br> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">A / sum_A</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[0.0000, 0.1429, 0.2222, 0.2727, 0.3077],</span></span><br><span class="line"><span class="string">        [1.0000, 0.8571, 0.7778, 0.7273, 0.6923]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[0.4000, 0.4074, 0.4138, 0.4194, 0.4242],</span></span><br><span class="line"><span class="string">        [0.6000, 0.5926, 0.5862, 0.5806, 0.5758]]])</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure></p>
<h5><span id="cumsum">cumsum</span></h5> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">A.cumsum(axis=<span class="number">0</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0.,  1.,  2.,  3.,  4.],</span></span><br><span class="line"><span class="string">        [ 5.,  6.,  7.,  8.,  9.]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">       [[10., 12., 14., 16., 18.],</span></span><br><span class="line"><span class="string">        [20., 22., 24., 26., 28.]]]) &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h4><span id="4254-dot-product">4.2.5.4 Dot Product</span></h4><p>mathmatical defination:</p>
<script type="math/tex; mode=display">
x,y \in R,\  x^Ty = \\sum_{i=1}^{d}x_{i}y_{i}</script><p>Each elements in Corresponding location multipys,then sum up.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y = torch.ones(<span class="number">3</span>, dtype = torch.float32)</span><br><span class="line">x, y, torch.dot(x, y)</span><br><span class="line"><span class="comment">#(tensor([0., 1., 2.]), tensor([1., 1., 1.]), tensor(3.))</span></span><br></pre></td></tr></table></figure><br>or:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch.dot(x, y) == torch.<span class="built_in">sum</span>(x*y)</span><br><span class="line"><span class="comment">#tensor(True)</span></span><br></pre></td></tr></table></figure></p>
<p> It can be expressed as a  _weighted average_</p>
<h4><span id="4255-matrix-vector-product">4.2.5.5 Matrix-Vector Product</span></h4><p><code>mv</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A.shape, x.shape, torch.mv(A, x), A@x</span><br><span class="line"><span class="comment">#(torch.Size([2, 3]), torch.Size([3]), tensor([3., 3.]), tensor([3., 3.]))</span></span><br></pre></td></tr></table></figure>
<h4><span id="4256-matrix-matrix-product">4.2.5.6 Matrix-Matrix Product</span></h4><p><code>mm</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">B = torch.ones(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">torch.mm(A, B), A@B</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">(tensor([[3., 3., 3., 3.],</span></span><br><span class="line"><span class="string">         [3., 3., 3., 3.]]),</span></span><br><span class="line"><span class="string"> tensor([[3., 3., 3., 3.],</span></span><br><span class="line"><span class="string">         [3., 3., 3., 3.]]))&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h4><span id="4257-norm">4.2.5.7 Norm</span></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">u = torch.tensor([<span class="number">3.0</span>, -<span class="number">4.0</span>])</span><br><span class="line">torch.norm(u),torch.<span class="built_in">abs</span>(u).<span class="built_in">sum</span>()</span><br><span class="line"><span class="comment">#(tensor(5.), tensor(7.))</span></span><br></pre></td></tr></table></figure>

            <div class="clearfix"></div>
            <hr class="nogutter">
        </div>
        <nav class="m-pagination col-md-8 col-md-offset-2 col-sm-24" role="pagination">
    
    <a class="pull-left" href="../%E9%9A%8F%E8%AE%B0-007/" style="float: left;">
        ← 随记-007
    </a>
    
    
    <a class="pull-right" href="../D2L_005_Calculus/">
        05_Calculus →
    </a>
    
</nav>

        <div class="col-md-8 col-md-offset-2 col-sm-24"><script type="text/javascript">
  /**
   * 搜狐畅言
   */

  /*
  document.write('<div id="SOHUCS" sid="' + window.location.pathname.slice(1) + '" ></div>');

  window.onload = function () {
    (function () {
      var appid = 'cytXXXX';
      var conf = 'prod_xxxxxxxxxxxxxxxxx';
      var width = window.innerWidth || document.documentElement.clientWidth;
      var loadJs = function (d, a, id) {
        var c = document.getElementsByTagName("head")[0] || document.head || document.documentElement;
        var b = document.createElement("script");
        b.setAttribute("type", "text/javascript");
        b.setAttribute("charset", "UTF-8");
        b.setAttribute("src", d);
        if (id) {
          b.setAttribute("id", id);
        }
        if (typeof a === "function") {
          if (window.attachEvent) {
            b.onreadystatechange = function () {
              var e = b.readyState;
              if (e === "loaded" || e === "complete") {
                b.onreadystatechange = null;
                a()
              }
            }
          } else {
            b.onload = a
          }
        }
        c.appendChild(b)
      };

      loadJs("https://changyan.sohu.com/upload/changyan.js", function () {
        window.changyan.api.config({
          appid: appid,
          conf: conf
        })
      });
    })();
  }
  */

</script>
</div>
    </div>
</section>

<!-- Highlight.js -->

<link rel="stylesheet"
href="//highlightjs.org/static/demo/styles/atom-one-light.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js">
</script>
<script>
hljs.initHighlightingOnLoad();

</script>


      
<!-- ============================ Footer =========================== -->

<footer>
    <div class="container">
            <div class="copy">
                <p>
                    &copy; 2014<script>new Date().getFullYear()>2010&&document.write("-"+new Date().getFullYear());</script>, Content By Rin777. All Rights Reserved.
                </p>
                <p>Theme By <a target="_blank" rel="noopener" href="//go.kieran.top" style="color: #767D84">Kieran</a></p>
            </div>
            <div class="social">
                <ul>
                    
                    <li><a href="https://github.com/" title="Github" target="_blank"><i class="icon-github"></i></a>&nbsp;</li>
                    
                    
                    
                    
                    
                </ul>
            </div>
            <div class="clearfix"> </div>
        </div>
</footer>

<!-- ============================ END Footer =========================== -->
      <!-- Load our scripts -->
<!-- Resizable 'on-demand' full-height hero -->
<script type="text/javascript">
    var resizeHero = function () {
        var hero = $(".cover,.heightblock"),
            window1 = $(window);
        hero.css({
            "height": window1.height()
        });
    };

    resizeHero();

    $(window).resize(function () {
        resizeHero();
    });
</script>
<script src="/js/plugins.min.js"></script><!-- Bootstrap core and concatenated plugins always load here -->
<script src="/js/scripts.js"></script><!-- Theme scripts -->


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$('#intro').find('img').each(function(){
  var alt = this.alt;

  if (alt){
    $(this).after('<span class="caption" style="display:none">' + alt + '</span>');
  }

  $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox" rel="gallery" />');
});
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



      
            <style>
.local-search-popup {
  display: none;
  position: fixed;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  padding: 0;
  background: rgba(255, 255, 255, .9);
  color: #333;
  z-index: 9999;
  border-radius: 5px;
  overflow: scroll;
}
#local-search-input {
  width: 100%;
  border: none;
  outline: none;
  border-bottom: 1px solid #151515;
  background-color: initial;
}
.search-result-list {
  list-style: none;
  padding-left: 0;
}
.search-result-list > li {
  margin-top: 15px;
  border-bottom: 1px solid #ddd;
  transition: all ease .3s;
}
.search-result-list > li:hover {
  border-bottom: 1px solid gray;
}
.search-result-title {
  font-size: 16px;
}
.search-result {
  line-height: 20px;
}
.search-keyword {
  font-weight: normal;
  color: #c00;
}

@media (min-width: 890px) {
  .popup-btn-close {
    position: absolute;
    top: 15px;
    left: 35px;
    border: 1px solid #151515;
    padding: 0px 10px;
    border-top-left-radius: 8px;
    cursor: pointer;
    transition: all ease .3s;
  }
  .popup-btn-close:hover {
    background: #151515;
    opacity: .9;
    color: #fff;
  }
}
@media (max-width: 890px) {
  .popup-btn-close {
    font-size: 0;
    position: fixed;
    right: 20px;
    bottom: 50px;
    width: 50px;
    height: 50px;
    background: #fff;
    border-radius: 50%;
    box-shadow: 1px 1px 5px #888;
    cursor: pointer;
  }
  .popup-btn-close::after {
    content: '←';
    color: #151515;
    position: absolute;
    top: 0;
    left: 0;
    font-size: 20px;
    width: 100%;
    height: 100%;
    line-height: 50px;
    text-align: center;
  }
}
</style>

<div class="popup search-popup local-search-popup">
  <span class="popup-btn-close">
    ESC
  </span>
  <div class="container">
    <div class="col-md-8 col-md-offset-2">
      <div class="local-search-header clearfix">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="local-search-input-wrapper">
          <input autocomplete="off" placeholder="Search..." type="text" id="local-search-input">
        </div>
      </div>
      <div id="local-search-result"></div>
    </div>
  </div>
</div>

<script src="/js/ziploader.js"></script>


  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.json";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').fadeOut(300);
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $('.popup').fadeIn(300);
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // get search zip version
    $.get('/searchVersion.txt?t=' + (+new Date()), function(res) {
      if (localStorage.getItem('searchVersion') !== res) {
        localStorage.setItem('searchVersion', res);
        initSearchJson();
      }
    });

    function initSearchJson () {
      initLoad(['/search.zip'], {
        loadOptions: {
          success: function(obj) {
            localStorage.setItem('searchJson', obj['search.json'])
          },
          error: function(e) {
            return console.log(e)
          }
        },
        returnOptions: {
          'json': TYPE_TEXT
        },
        mimeOptions:{
          'json':'application/json'
        }
      })
    }


    // search function;
    var searchFunc = function(search_id, content_id) {
      'use strict';

      isfetched = true;
      var datas = JSON.parse(localStorage.getItem('searchJson'));
      console.log(search_id)
      var input = document.getElementById(search_id);
      var resultContent = document.getElementById(content_id);
      var inputEventFunction = function() {
        var searchText = input.value.trim().toLowerCase();
        var keywords = searchText.split(/[\s\-]+/);
        if (keywords.length > 1) {
          keywords.push(searchText);
        }
        var resultItems = [];
        if (searchText.length > 0) {
          // perform local searching
          datas.forEach(function(data) {
            var isMatch = false;
            var hitCount = 0;
            var searchTextCount = 0;
            var title = data.title ? data.title.trim() : '';
            var titleInLowerCase = title.toLowerCase();
            var content = data.content ? data.content.trim().replace(/<[^>]+>/g,"") : '';
            var contentInLowerCase = content.toLowerCase();
            var articleUrl = decodeURIComponent(data.url);
            var indexOfTitle = [];
            var indexOfContent = [];
            // only match articles with not empty titles
            keywords.forEach(function(keyword) {
              function getIndexByWord(word, text, caseSensitive) {
                var wordLen = word.length;
                if (wordLen === 0) {
                  return [];
                }
                var startPosition = 0, position = [], index = [];
                if (!caseSensitive) {
                  text = text.toLowerCase();
                  word = word.toLowerCase();
                }
                while ((position = text.indexOf(word, startPosition)) > -1) {
                  index.push({position: position, word: word});
                  startPosition = position + wordLen;
                }
                return index;
              }

              indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
              indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
            });
            if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
              isMatch = true;
              hitCount = indexOfTitle.length + indexOfContent.length;
            }

            // show search results

            if (isMatch) {
              // sort index by position of keyword

              [indexOfTitle, indexOfContent].forEach(function (index) {
                index.sort(function (itemLeft, itemRight) {
                  if (itemRight.position !== itemLeft.position) {
                    return itemRight.position - itemLeft.position;
                  } else {
                    return itemLeft.word.length - itemRight.word.length;
                  }
                });
              });

              // merge hits into slices

              function mergeIntoSlice(text, start, end, index) {
                var item = index[index.length - 1];
                var position = item.position;
                var word = item.word;
                var hits = [];
                var searchTextCountInSlice = 0;
                while (position + word.length <= end && index.length != 0) {
                  if (word === searchText) {
                    searchTextCountInSlice++;
                  }
                  hits.push({position: position, length: word.length});
                  var wordEnd = position + word.length;

                  // move to next position of hit

                  index.pop();
                  while (index.length != 0) {
                    item = index[index.length - 1];
                    position = item.position;
                    word = item.word;
                    if (wordEnd > position) {
                      index.pop();
                    } else {
                      break;
                    }
                  }
                }
                searchTextCount += searchTextCountInSlice;
                return {
                  hits: hits,
                  start: start,
                  end: end,
                  searchTextCount: searchTextCountInSlice
                };
              }

              var slicesOfTitle = [];
              if (indexOfTitle.length != 0) {
                slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
              }

              var slicesOfContent = [];
              while (indexOfContent.length != 0) {
                var item = indexOfContent[indexOfContent.length - 1];
                var position = item.position;
                var word = item.word;
                // cut out 100 characters
                var start = position - 20;
                var end = position + 80;
                if(start < 0){
                  start = 0;
                }
                if (end < position + word.length) {
                  end = position + word.length;
                }
                if(end > content.length){
                  end = content.length;
                }
                slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
              }

              // sort slices in content by search text's count and hits' count

              slicesOfContent.sort(function (sliceLeft, sliceRight) {
                if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                  return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                  return sliceRight.hits.length - sliceLeft.hits.length;
                } else {
                  return sliceLeft.start - sliceRight.start;
                }
              });

              // select top N slices in content

              var upperBound = parseInt('2');
              if (upperBound >= 0) {
                slicesOfContent = slicesOfContent.slice(0, upperBound);
              }

              // highlight title and content

              function highlightKeyword(text, slice) {
                var result = '';
                var prevEnd = slice.start;
                slice.hits.forEach(function (hit) {
                  result += text.substring(prevEnd, hit.position);
                  var end = hit.position + hit.length;
                  result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                  prevEnd = end;
                });
                result += text.substring(prevEnd, slice.end);
                return result;
              }

              var resultItem = '';

              if (slicesOfTitle.length != 0) {
                resultItem += "<li><a target='_blank' href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
              } else {
                resultItem += "<li><a target='_blank' href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
              }

              slicesOfContent.forEach(function (slice) {
                resultItem += "<a target='_blank' href='" + articleUrl + "'>" +
                  "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                  "...</p>" + "</a>";
              });

              resultItem += "</li>";
              resultItems.push({
                item: resultItem,
                searchTextCount: searchTextCount,
                hitCount: hitCount,
                id: resultItems.length
              });
            }
          })
        };
        if (keywords.length === 1 && keywords[0] === "") {
          resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
        } else if (resultItems.length === 0) {
          resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
        } else {
          resultItems.sort(function (resultLeft, resultRight) {
            if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
              return resultRight.searchTextCount - resultLeft.searchTextCount;
            } else if (resultLeft.hitCount !== resultRight.hitCount) {
              return resultRight.hitCount - resultLeft.hitCount;
            } else {
              return resultRight.id - resultLeft.id;
            }
          });
          var searchResultList = '<ul class=\"search-result-list\">';
          resultItems.forEach(function (result) {
            searchResultList += result.item;
          })
          searchResultList += "</ul>";
          resultContent.innerHTML = searchResultList;
        }
      }

      if ('auto' === 'auto') {
        input.addEventListener('input', inputEventFunction);
      } else {
        $('.search-icon').click(inputEventFunction);
        input.addEventListener('keypress', function (event) {
          if (event.keyCode === 13) {
            inputEventFunction();
          }
        });
      }

      // remove loading animation
      $('body').css('overflow', '');

      proceedsearch();
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        $('.sb-close').click();
        searchFunc('local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>


      
      

<!--

<link rel="stylesheet" href="/dist/APlayer.min.css">
<div id="aplayer"></div>
<script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script>

<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>
<meting-js
      server="netease"
      type="playlist"
      id="4904272454">
</meting-js>
-->

</body>

</html>







